x<-c(1,3,5)
y<-c(3,2,10)
rbind(x,y)
x<-list(2,"a","b",TRUE)
x[[2]]
x<-1:4
y<-2
x+y
x<-c(3,5,1,10,12,6)
x[x==0]<6
x[x<0]<-0
x
x[x<6]<-0
x
ls
cd
cd
hw1_data <- read.csv("H:/Dropbox/CS/RProgramming/hw1_data.csv")
View(hw1_data)
Ozone <- hw1_data[,1]
isBda
is
isBad
bad<-is.na(Ozone)
Ozone[bad]
length(Ozone[bad])
mean(Ozone(!bad))
mean(Ozone[!bad])
temp <- hw1_data[Ozone>31 && Temp >90]
hw1_data[Ozone>31 && Temp >90]
temp = hw1_data
clear
temp <- hw1_data[which(hw1_data$Ozone>31 & hw1_data$Temp>90)]
temp1 <- hw1_data[which(hw1_data$Ozone>31 & hw1_data$Temp>90)]
temp1 <- hw1_data[which(hw1_data$Ozone>31 & hw1_data$Temp>90),]
mean(temp1["Solar.R"])
temp1["Solar.R"]
temp1["Solar.R"]
temp1
mean(temp1[,3])
mean(temp1[,2])
temp2 <- hw1_data[which(hw1_data$Month == 6),]
temp2["Temp"]
Temp_temp2 <- temp2["Temp"]
mean(Temp_temp2)
mean(Temp_temp2[1])
mean(Temp_temp2[1,])
mean(Temp_temp2[,1])
temp2 <- hw1_data[which(hw1_data$Month == 5),]
temp2
Ozone_temp2<- temp2["Ozone"]
max(Ozone_temp2[,1])
x<-c(4,"a",TRUE)
x<4
x>=4
x<-4
x<-4L
x<-c(4,TRUE)
x<-list(2,"a","b",TRUE)
x[[1]]
y<-x[[1]]
x<-c(3,5,1,10,12,6)
x[x<6] == 0
x<-c(4,"a",TRUE)
x<-c(1,3,5)
y<-c(3,2,10)
cbind(x,y)
rbind(x,y)
type(rbind(x,y))
class(rbind(x,y))
z = cbind(x,y)
x<-c(0.18,-1.54,0.42,0.95)
w<-c(2,1,3,1)
x-0.1471
w*(x-0.1471)*(x-0.1471)
sum(w*(x-0.1471)*(x-0.1471))
sum(w*(x-1.077)*(x-1.077))
sum(w*(x-0.0025)*(x-0.0025))
sum(w*(x-0.3)*(x-0.3))
?pnorm
qnorm(0.16,mean=80,sd=10)
qnorm(0.22,mean=80,sd=10)
qnorm(0.8,mean=80,sd=10)
pnorm(70,mean=80,sd=10)
qnorm(0.95,mean=1100,sd=75)
qnorm(0.95,mean=1100,sd=75/100)
qnorm(0.95,mean=1100,sd=sqrt(75^2/100))
ppois(3,lambda = 5)
ppois(3,lambda = 5*0.5)
pbinom(3,size=5,prob = 0.5)
1-0.8125
pnorm(14,mean=15,sd=sqrt(10^2/100))
pnorm(16,mean=15,sd=sqrt(10^2/100))
1-last
1-.Last.value
pnorm(-1)
pnorm(1)
pnorm(1)-pnorm(-1)
qnorm(0)
qnorm(0.5)
1/12/sqrt(1000)
sqrt(.Last.value)
sqrt(1/12)/sqrt(1000)
sqrt(1/12)
ppois(10,lambda = 5*3)
rm(list=ls())
x <- mtcars$wt
y <- mtcars$mpg
fit <- lm(y~x)
newdata = data.frame(wt = 3)
predict(fit,newdata,interval="predict")
fit <- lm(y~x)
newdata = data.frame(x = 3)
predict(fit,newdata,interval="predict")
newdata = data.frame(x = 2)
predict(fit,newdata,interval="confidence")
library(UsingR)
install.packages("UsingR")
library(UsingR)
data(diamond)
rm(list=ls())
data(diamond)
?diamond
View(diamond)
x <- mtcars$wt
y <- mtcars$mpg
fit<-lm(y~x)
sumCoef<-summary(fit)$coefficients
sumCoef[2,1]+c(-1,1)*qt(.975,df=fit$df)*sumCoef[2,2]
summary(fit)
predict(fit,newdata,interval="predict")
newdata = data.frame(x = mean(x))
predict(fit,newdata,interval="predict")
predict(fit,newdata,interval="confident")
predict(fit,newdata,interval="confidence")
rm(fit)
rm(diamond)
rm(newdata)
rm(sumC)
rm(sumCoef)
fit_1(y~x)
fit_1<-lm(y~x)
y_real <- y
y_m1 <- fit_1$coef[1]+fit_1$coef[2]*x
y_m2 <- mean(y)
(y_real-y_m1)^2
sum(y_real-y_m1)^2
sum((y_real-y_m1)^2)
sum((y_real-y_m2)^2)
sum((y_real-y_m1)^2)/ sum((y_real-y_m2)^2)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
install.packages("caret")
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
install.packages("AppliedPredictiveModeling")
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
rm(list=ls())
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
names <- c("IL_11","IL_13","IL_16","IL_17E","IL_1alpha","IL_3","IL_4","IL_5","IL_6","IL_6_Receptor","IL_7","IL_8")
?train
trainFit <- train(diagnosis ~.,data = training(names),method = "glm")
trainFit <- train(diagnosis ~.,data = training[names],method = "glm")
class(training[names])
dim(training[names])
setwd("H:/Dropbox/CS/DataScience/CollectingData/Assignment/collectNcleanData")
list.filename
list.file
list.files
list.files()
is.empty
is.null
is.null()
is.files()
message("Can not find local dataset, start to download from website")
}
directory <- ('~/UCI HAR Dataset/')
file_name <- list.files(directroy,full.names=T)
directory <- ('~/UCI HAR Dataset/')
file_name <- list.files(directory,full.names=T)
directory <- ("UCI HAR Dataset")
file_name <- list.files(directory,full.names=T)
# Data Source: University of California, Irvine - Machine Learning Repository
# Dataset Name: Human Activity Recognition Using Smartphones Data Set
# Resource link: http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones
# Data Download Link: https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip
# Part I. Load and Read Datasets from file/internet
# Check data
ddata = function(){
# Directory of file
directory <- ("UCI HAR Datase")
# Make a list of file names
file_name <- list.files(directory,full.names=T)
# Check whether the local file exist, if not, download from website and unzip
if(is.null(file_name)){
message("Can not find local dataset, start to download from website")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileUrl, destfile = "Dataset.zip", method = "curl")
unzip("Dataset.zip")
}
}
# Read in data
rdata = function(){
}
source("run_analysis.R")
ddata
ddata()
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileUrl, destfile = "Dataset.zip", method = "curl")
unzip("Dataset.zip")
message("Can not find local dataset, start to download from website")
fileUrl <- "http://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileUrl, destfile = "Dataset.zip", method = "curl")
unzip("Dataset.zip")
message("Can not find local dataset, start to download from website")
fileUrl <- "http://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileUrl, destfile = "Dataset.zip", method = "curl")
unzip("Dataset.zip")
message("Can not find local dataset, start to download from website")
fileUrl <- "http://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileUrl, destfile = "Dataset.zip")
directory <- ("UCI HAR Datase")
# Make a list of file names
file_name <- list.files(directory,full.names=T)
is.null(file_name
)
directory <- ("UCI HAR Dataset")
# Make a list of file names
file_name <- list.files(directory,full.names=T)
is.null(file_name
)
is.list(file_name)
directory <- ("UCI HAR Datase")
# Make a list of file names
file_name <- list.files(directory,full.names=T)
is.list(file_name)
length(file_name) == 0
isempty
source("run_analysis.R")
ddata
ddata()
ddata()
ddata()
source("run_analysis.R")
ddata()
source("run_analysis.R")
rdata
rdata()
rdata<-rdata
rdata<-rdata()
source("run_analysis.R")
rdata<-rdata()
train_X <- read.table("UCI HAR Dataset/train/X_train.txt")
train_Y <- read.table("UCI HAR Dataset/train/y_train.txt")
train_Subject <- read.table("UCI HAR Dataset/train/subject_train.txt")
file_name <- list("UCI HAR Dataset/train")
file_name <- list.files("UCI HAR Dataset/train")
train_X <- read.table("UCI HAR Dataset/train/X_train.txt")
source("run_analysis.R")
rdata
rdata()
message("Can not find local dataset, start to download from website .../n ......")
source("run_analysis.R")
rdata()
test_X <- read.table("UCI HAR Dataset/test/X_test.txt")
test_Y <- read.table("UCI HAR Dataset/test/y_test.txt")
test_Subject <- read.table("UCI HAR Dataset/test/subject_test.txt")
mergeX <- rbind(train_X,test_X)
mergeY <- rbind(train_Y,test_Y)
mergeSubject <- rbind(train_Subject,test_Subject)
source("run_analysis.R")
ddata
ddata()
a <- rdata
View(test_Y)
rm(list=ls())
source("run_analysis.R")
ddata()
a <- rdata
a <- rdata()
source("run_analysis.R")
extract_data
extract_data()
features = read.table("UCI HAR Dataset/features.txt", sep="", header=FALSE)
?names
features[,2] = gsub('-mean', 'Mean', features[,2])
features[,2] = gsub('-std', 'Std', features[,2])
features[,2] = gsub('[-()]', '', features[,2])
View(features)
features = read.table("UCI HAR Dataset/features.txt", sep="", header=FALSE)
View(features)
features = read.table("UCI HAR Dataset/features.txt", sep="", header=FALSE)
features[,2] = gsub('-mean', 'Mean', features[,2])
features[,2] = gsub('-std', 'Std', features[,2])
features[,2] = gsub('[-()]', '', features[,2])
source('H:/Dropbox/CS/DataScience/CollectingData/Assignment/collectNcleanData/run_analysis.R')
source('H:/Dropbox/CS/DataScience/CollectingData/Assignment/collectNcleanData/run_analysis.R')
source('~/.active-rstudio-document')
source('H:/Dropbox/CS/DataScience/CollectingData/Assignment/collectNcleanData/run_analysis.R')
label_act <- read.table("UCI HAR Dataset/activity_labels.txt")[,2]
View(test_Y)
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
View(test_Subject)
name(mergeY) <- c("Activity Label","Activity Name")
names(mergeY) <- c("Activity Label","Activity Name")
View(mergeY)
source('H:/Dropbox/CS/DataScience/CollectingData/Assignment/collectNcleanData/run_analysis.R')
View(mergeX)
source('H:/Dropbox/CS/DataScience/CollectingData/Assignment/collectNcleanData/run_analysis.R')
?setdiff
?rbind
?bind.data
?bind
?ddply
source('H:/Dropbox/CS/DataScience/CollectingData/Assignment/collectNcleanData/run_analysis.R')
ext_features <- grepl("mean|std", features)
mergeData$x <- mergeData$x[,ext_features]
a <- mergeData$x[,ext_features]
View(a)
View(a)
View(a)
source('~/.active-rstudio-document')
tidy <- ddply(mergeData, .(subject, activity), function(x) colMeans(x[,1:60]))
library(plyr)
tidy <- ddply(mergeData, .(subject, activity), function(x) colMeans(x[,1:60]))
view(mergeData)
summary(mergeData)
source('H:/Dropbox/CS/DataScience/CollectingData/Assignment/collectNcleanData/run_analysis.R')
temp <- cbind(mergeData$x,mergeData$y,mergeData$subject)
tidy <- ddply(temp, .(subject, activity), function(x) colMeans(x[,1:60]))
temp <- cbind(mergeData$x,mergeData$y,mergeData$subject)
tidy <- ddply(temp, .(subject, ActivityName), function(x) colMeans(x[,1:60]))
write.csv(tidy, "UCI_HAR_tidy.csv", row.names=FALSE)
?ddply
